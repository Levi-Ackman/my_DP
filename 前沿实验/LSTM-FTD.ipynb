{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904f1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np\n",
    "\n",
    "y=io.loadmat(\"D:\\\\机器学习前沿实验\\\\实验课一\\\\dataset\\\\FTD_90_200_fMRI.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dfefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Sep 15 16:13:18 2021',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'FTD': array([[[ 2.50049135,  2.48836375,  0.76244127, ...,  1.58452119,\n",
       "           2.1307843 ,  2.38140009],\n",
       "         [ 2.45768574,  2.41266857, -0.78422818, ...,  2.03407663,\n",
       "           2.03950974,  2.64254884],\n",
       "         [-1.64347569, -0.44281807, -1.44156423, ...,  1.48753878,\n",
       "           2.09132309,  2.80178515],\n",
       "         ...,\n",
       "         [ 0.70175193, -0.33569285, -0.08657972, ...,  1.94723672,\n",
       "           1.99002767,  2.97593009],\n",
       "         [-0.8417131 , -0.32816934,  0.30816443, ...,  1.11815507,\n",
       "           1.74715135,  2.90560077],\n",
       "         [-0.60596173, -0.65205069, -0.38014939, ...,  2.07912456,\n",
       "           2.80800418,  3.82354762]],\n",
       " \n",
       "        [[-3.21530128,  0.74852721, -0.94472378, ...,  3.17270744,\n",
       "           3.55779983,  0.58324881],\n",
       "         [-8.56478122, -2.44259909, -0.91971577, ...,  0.88943393,\n",
       "           2.2078903 , -1.95835273],\n",
       "         [-3.57067398, -0.09215326, -2.37065259, ..., -1.23390375,\n",
       "           2.92181432,  0.15166168],\n",
       "         ...,\n",
       "         [-3.32330634, -3.30559905, -5.30694526, ..., -8.35705564,\n",
       "          -1.01469149, -1.68214944],\n",
       "         [ 0.45390862,  0.30576977, -2.9737133 , ..., -2.59348251,\n",
       "          -1.77593426, -2.03143815],\n",
       "         [-5.45173489, -3.77432559, -5.13705735, ..., -3.29124803,\n",
       "          -0.08936908, -1.64725145]],\n",
       " \n",
       "        [[-1.28531413, -0.55786337,  0.8570272 , ...,  3.69492544,\n",
       "           3.42264293,  2.9857751 ],\n",
       "         [-2.2961486 , -1.46438875, -0.66350645, ...,  3.448851  ,\n",
       "           1.13887165,  5.13214107],\n",
       "         [ 1.79414123,  1.3312445 ,  2.96772751, ...,  2.30753822,\n",
       "           2.03466921,  1.45908298],\n",
       "         ...,\n",
       "         [-0.73826915, -0.17819397,  2.17064782, ...,  1.88289561,\n",
       "           3.25453237,  2.92840601],\n",
       "         [ 1.24250082,  1.44510754,  2.63839068, ...,  1.28649029,\n",
       "           1.65911048,  1.50015372],\n",
       "         [ 0.10513281, -0.38993876,  0.9696375 , ...,  2.14634581,\n",
       "           2.84851913,  3.46818663]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-5.36068024, -2.28725528, -1.90801187, ..., -0.15575392,\n",
       "          -3.52085396, -2.38799337],\n",
       "         [-4.84085431, -2.26986836, -2.4015063 , ..., -0.39942938,\n",
       "          -3.11751584, -1.75818731],\n",
       "         [-3.57623914, -1.29894756, -1.51170448, ...,  0.08797211,\n",
       "          -2.4924799 , -1.93936047],\n",
       "         ...,\n",
       "         [-2.28175304, -0.75864155, -0.34885043, ...,  1.09059062,\n",
       "          -0.40727826, -0.28013962],\n",
       "         [-2.35187067, -0.93556422, -1.16533384, ...,  0.64856469,\n",
       "          -0.77990424, -0.5341664 ],\n",
       "         [-2.83156213, -1.27905695, -1.54997572, ...,  0.31845093,\n",
       "          -1.25233896, -0.69170025]],\n",
       " \n",
       "        [[ 0.55025121,  1.23604833, -0.47323514, ..., -1.14680974,\n",
       "          -0.62867346,  0.55775298],\n",
       "         [-1.69606421, -0.20700375, -1.48653163, ..., -1.66675591,\n",
       "          -1.64116044, -0.02540063],\n",
       "         [ 0.43771637, -0.48579999, -1.73491429, ..., -0.48045631,\n",
       "          -0.25999949, -0.06700955],\n",
       "         ...,\n",
       "         [ 0.74818673,  2.11062226,  0.76235895, ..., -0.41831363,\n",
       "           0.5665979 ,  2.40268057],\n",
       "         [ 0.66781689,  1.5649972 ,  0.79874604, ...,  0.57342163,\n",
       "           1.33067828,  1.9449084 ],\n",
       "         [ 0.13405618,  0.55178817, -0.71524826, ...,  0.44433424,\n",
       "           0.37430077,  0.79692006]],\n",
       " \n",
       "        [[ 0.15035958,  0.80077385, -0.52211798, ...,  0.46754309,\n",
       "          -0.7645291 , -2.27764073],\n",
       "         [ 0.79765308,  1.05092697, -0.2848001 , ...,  0.26628718,\n",
       "          -0.57519259, -1.67298481],\n",
       "         [ 0.739876  ,  0.71268589,  0.34557151, ...,  0.75067731,\n",
       "          -0.00877271, -1.34569883],\n",
       "         ...,\n",
       "         [ 0.58737005,  0.64446993, -0.05338815, ...,  0.02430594,\n",
       "          -1.09724326, -2.30642557],\n",
       "         [-0.88770727,  0.02215216, -1.24698553, ...,  0.24938404,\n",
       "          -0.82071685, -2.18622784],\n",
       "         [ 0.05293387,  0.64360252,  0.28990342, ...,  0.11310307,\n",
       "          -0.55541434, -1.02757926]]]),\n",
       " 'NC': array([[[ 1.90604161,  1.87136215,  0.87836931, ..., -3.35812045,\n",
       "          -3.18717631, -2.78624051],\n",
       "         [ 1.16876506,  0.91108417,  0.53755276, ..., -3.79591638,\n",
       "          -4.94053534, -3.97482433],\n",
       "         [ 0.42850733,  0.12663756,  0.17133211, ..., -2.53251507,\n",
       "          -2.48354671, -3.08608978],\n",
       "         ...,\n",
       "         [-0.90126307,  0.13759023,  0.20630264, ..., -1.15491113,\n",
       "          -1.47163641, -1.96412874],\n",
       "         [-0.20835893,  0.62974547,  0.58834601, ..., -1.70803361,\n",
       "          -2.77053861, -3.19812109],\n",
       "         [ 0.26416518,  0.98374407,  1.47911251, ..., -1.22544237,\n",
       "          -1.27290029, -1.13974858]],\n",
       " \n",
       "        [[ 1.93221379,  1.67964752,  1.64293239, ..., -0.11400914,\n",
       "           4.24723588,  5.33159336],\n",
       "         [-0.73770416,  0.87870633,  3.35771479, ..., -1.5689322 ,\n",
       "           1.60883231,  1.75580793],\n",
       "         [-0.20888236, -1.16544023, -0.34314498, ..., -4.77738161,\n",
       "           0.08452963,  2.8598536 ],\n",
       "         ...,\n",
       "         [-0.08798806, -1.87076374, -0.93464872, ..., -1.16764071,\n",
       "           0.32122657,  2.44310024],\n",
       "         [ 1.93799144,  0.82534006,  0.95401597, ..., -2.02563947,\n",
       "           0.20306341,  1.41851927],\n",
       "         [-0.96816498, -1.95321434, -1.69866655, ...,  2.34596631,\n",
       "           3.39699891,  4.90250509]],\n",
       " \n",
       "        [[-1.02754463, -0.48985138,  0.00928575, ...,  0.1729472 ,\n",
       "           0.38519184,  0.76840598],\n",
       "         [ 0.20028767, -0.47790889, -1.36492662, ...,  0.11340547,\n",
       "           1.09048152,  1.02629756],\n",
       "         [-1.93852567, -0.15057631,  1.93508313, ..., -0.90319603,\n",
       "           0.43695543,  2.03527727],\n",
       "         ...,\n",
       "         [ 0.98611683,  1.91571568,  2.22777249, ..., -1.5388914 ,\n",
       "          -1.60259747, -0.15573799],\n",
       "         [-1.18348034, -1.20466204, -0.0943066 , ...,  1.18632328,\n",
       "           0.02404127, -0.01343449],\n",
       "         [-0.20167802, -0.0255968 ,  0.12550915, ..., -0.59694142,\n",
       "          -0.19640175,  0.52134139]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-4.59763936, -4.80851447, -6.82474128, ..., -1.60570368,\n",
       "           1.88710776,  2.32438256],\n",
       "         [ 3.51856806,  4.56485107,  0.02721423, ..., -5.44223177,\n",
       "          -1.52850695,  0.22363044],\n",
       "         [-1.10911119, -2.14966468, -4.71594343, ..., -1.34731199,\n",
       "           3.36417587,  4.55655759],\n",
       "         ...,\n",
       "         [-0.89522869, -0.66405559, -2.09825136, ..., -1.02833629,\n",
       "           0.91809855,  1.76459257],\n",
       "         [ 0.72664686,  3.38746943,  3.26901853, ...,  0.70063766,\n",
       "          -1.15169488, -2.61746333],\n",
       "         [ 1.96817868,  2.12499793,  0.31780848, ...,  1.25556803,\n",
       "           1.63420183, -1.25130311]],\n",
       " \n",
       "        [[ 1.02873356,  1.06284435, -1.51118711, ..., -2.06430865,\n",
       "          -0.94928771, -0.73005308],\n",
       "         [ 2.08425242,  1.87413873,  0.19689392, ..., -0.15710624,\n",
       "           0.71464454,  0.25868304],\n",
       "         [ 0.6037805 ,  1.63513776, -0.47580424, ..., -1.43542078,\n",
       "          -1.88450452, -2.514441  ],\n",
       "         ...,\n",
       "         [ 0.55036108,  2.84195867,  3.47759351, ...,  0.57721727,\n",
       "          -0.20405974, -1.35134998],\n",
       "         [-0.52388721,  1.47820094,  0.77777671, ..., -0.44784099,\n",
       "           0.09692377,  0.10932884],\n",
       "         [-0.48657737,  1.69483144,  1.32760409, ...,  0.4927863 ,\n",
       "           0.28644722, -0.09994829]],\n",
       " \n",
       "        [[-1.15812537, -1.57917125,  0.45577129, ..., -1.89107382,\n",
       "           1.20233396,  0.30274522],\n",
       "         [-0.69445873, -1.44676126, -0.19412679, ..., -1.33174772,\n",
       "           1.34241155,  0.69221048],\n",
       "         [-1.79771039, -1.40197591, -0.22786825, ..., -1.41742186,\n",
       "          -0.51442629, -1.73995416],\n",
       "         ...,\n",
       "         [-1.19004227, -0.98334105,  0.05368989, ..., -2.60227442,\n",
       "          -2.78741401, -1.96583281],\n",
       "         [-1.01810761,  0.3232755 ,  1.1764284 , ..., -1.68459574,\n",
       "          -2.2851874 , -2.35096461],\n",
       "         [-1.07990853,  0.20231388,  0.90305532, ..., -1.20512335,\n",
       "          -1.43531148, -1.87175958]]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73566ef",
   "metadata": {},
   "source": [
    "# 为数组打上标签，FTD=0  NC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a335f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "FTD=np.asarray(y['FTD'])\n",
    "FTD_lable=np.full((FTD.shape[0],1),0,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30ef300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 90, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FTD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44788f51",
   "metadata": {},
   "source": [
    "# 记录数组维度方便后续转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599a32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=FTD.shape[1]\n",
    "n=FTD.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "NC=np.asarray(y['NC'])\n",
    "NC_lable=np.full((NC.shape[0],1),1,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf5f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 90, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025aeff4",
   "metadata": {},
   "source": [
    "# 将数据转换为2维，方便后续数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee80459",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = FTD.reshape(FTD.shape[0],-1)\n",
    "y = NC.reshape(NC.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f2f56",
   "metadata": {},
   "source": [
    "# 将数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c78745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label=np.vstack((FTD_lable,NC_lable))\n",
    "Data=np.vstack((x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d41fe",
   "metadata": {},
   "source": [
    "# 将数据转换为原本的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb42f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=(Data.reshape(-1,m, n))\n",
    "Data=Data.transpose((0,2,1))\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Label=to_categorical(Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5718cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 200, 90)\n",
      "(181, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)\n",
    "print(Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "469fdcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional,LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc603aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    " \n",
    "def scheduler(epoch):\n",
    "    # 每隔25个epoch，学习率减小为原来的1/10-lstm\n",
    "    #if epoch % 5 == 0 and epoch != 0:\n",
    "    if epoch % 25 == 0 and epoch != 0:\n",
    "#         lr = K.get_value(model.optimizer.lr*0.01)#LSTM\n",
    "        lr = K.get_value(model.optimizer.lr) #一维卷积\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    " \n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1872de",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77425fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model():\n",
    "    model = Sequential() #layers [128,64,32,16,4]\n",
    "    model.add(LSTM(input_shape=(None,90),units=200,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(input_shape=(None,50),units=128,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(input_shape=(None,50),units=64,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32,return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=2))\n",
    "    #model.add(Activation(\"linear\"))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    start = time.time()\n",
    "    model.compile(optimizer = 'rmsprop',                 # 加速神经网络\n",
    "        loss = 'categorical_crossentropy',   # 损失函数\n",
    "        metrics = ['accuracy'], )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237ec25",
   "metadata": {},
   "source": [
    "# 一维卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be16d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def built_model(input=128):\n",
    "#     model = Sequential()\n",
    "#     model.add(layers.Convolution1D(128,3,strides=1))\n",
    "#     model.add(layers.LayerNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(layers.Convolution1D(256,3,strides=1))\n",
    "#     model.add(layers.LayerNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(layers.Convolution1D(128,3,strides=1))\n",
    "#     model.add(layers.LayerNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(layers.GlobalAveragePooling1D())\n",
    "#     model.add(Dense(2, activation='softmax'))\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6aefcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold 5\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 13s 415ms/step - loss: 0.7128 - accuracy: 0.5278 - val_loss: 0.7194 - val_accuracy: 0.4595 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.6148 - accuracy: 0.6528 - val_loss: 0.7293 - val_accuracy: 0.5405 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 357ms/step - loss: 0.4527 - accuracy: 0.8056 - val_loss: 0.9482 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.2933 - accuracy: 0.9097 - val_loss: 0.7868 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 334ms/step - loss: 0.1643 - accuracy: 0.9444 - val_loss: 0.9417 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 6s 368ms/step - loss: 0.0517 - accuracy: 0.9931 - val_loss: 1.2423 - val_accuracy: 0.5405 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 344ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3796 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 329ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.5332 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 340ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 355ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8016 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 357ms/step - loss: 5.3958e-04 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 359ms/step - loss: 3.2429e-04 - accuracy: 1.0000 - val_loss: 2.1340 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 368ms/step - loss: 1.7059e-04 - accuracy: 1.0000 - val_loss: 2.5070 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 6s 367ms/step - loss: 7.5852e-05 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 6s 396ms/step - loss: 3.9336e-05 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 6s 396ms/step - loss: 2.7841e-05 - accuracy: 1.0000 - val_loss: 3.1110 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 6s 383ms/step - loss: 1.6179e-05 - accuracy: 1.0000 - val_loss: 3.2976 - val_accuracy: 0.6486 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 6s 379ms/step - loss: 9.0522e-06 - accuracy: 1.0000 - val_loss: 3.4762 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 6s 381ms/step - loss: 4.5928e-06 - accuracy: 1.0000 - val_loss: 3.5363 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 2.5605e-06 - accuracy: 1.0000 - val_loss: 3.4962 - val_accuracy: 0.6216 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 1.5969e-06 - accuracy: 1.0000 - val_loss: 3.7515 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 1.1333e-06 - accuracy: 1.0000 - val_loss: 3.8878 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 7.4671e-07 - accuracy: 1.0000 - val_loss: 3.8621 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 6s 383ms/step - loss: 5.5383e-07 - accuracy: 1.0000 - val_loss: 3.9014 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 6s 410ms/step - loss: 4.0730e-07 - accuracy: 1.0000 - val_loss: 4.0689 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "lr changed to 0.00010000000474974513\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 6s 389ms/step - loss: 1.7716e-07 - accuracy: 1.0000 - val_loss: 4.0854 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 2.3014e-07 - accuracy: 1.0000 - val_loss: 4.1118 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 6s 399ms/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 4.1207 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 6s 401ms/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 4.1393 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 6s 406ms/step - loss: 1.8130e-07 - accuracy: 1.0000 - val_loss: 4.1615 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 6s 410ms/step - loss: 2.1938e-07 - accuracy: 1.0000 - val_loss: 4.1782 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 1.9785e-07 - accuracy: 1.0000 - val_loss: 4.1942 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 4.2151 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 1.6557e-07 - accuracy: 1.0000 - val_loss: 4.2250 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 4.2164 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 1.7054e-07 - accuracy: 1.0000 - val_loss: 4.2303 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 6s 424ms/step - loss: 1.6640e-07 - accuracy: 1.0000 - val_loss: 4.2472 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 4.2509 - val_accuracy: 0.6486 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 3.4107e-07 - accuracy: 1.0000 - val_loss: 4.1749 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 1.1093e-07 - accuracy: 1.0000 - val_loss: 4.1888 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 6s 404ms/step - loss: 6.6391e-07 - accuracy: 1.0000 - val_loss: 4.1598 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 4.1659 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 7s 439ms/step - loss: 2.3179e-07 - accuracy: 1.0000 - val_loss: 4.1833 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 1.2666e-07 - accuracy: 1.0000 - val_loss: 4.1794 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 1.7136e-07 - accuracy: 1.0000 - val_loss: 4.2033 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 6s 398ms/step - loss: 1.4073e-07 - accuracy: 1.0000 - val_loss: 4.1930 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 6s 401ms/step - loss: 1.5149e-07 - accuracy: 1.0000 - val_loss: 4.2134 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 1.1507e-07 - accuracy: 1.0000 - val_loss: 4.2095 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 7s 437ms/step - loss: 1.9123e-07 - accuracy: 1.0000 - val_loss: 4.2275 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 1.2666e-07 - accuracy: 1.0000 - val_loss: 4.2542 - val_accuracy: 0.6757 - lr: 1.0000e-04\n",
      "lr changed to 1.0000000474974514e-05\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 428ms/step - loss: 7.8645e-08 - accuracy: 1.0000 - val_loss: 4.2555 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 2.5166e-07 - accuracy: 1.0000 - val_loss: 4.2570 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 1.2997e-07 - accuracy: 1.0000 - val_loss: 4.2607 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 4.2621 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 6s 395ms/step - loss: 8.0301e-08 - accuracy: 1.0000 - val_loss: 4.2639 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 1.8544e-07 - accuracy: 1.0000 - val_loss: 4.2662 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 2.3097e-07 - accuracy: 1.0000 - val_loss: 4.2662 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 8.1956e-08 - accuracy: 1.0000 - val_loss: 4.2685 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 1.3991e-07 - accuracy: 1.0000 - val_loss: 4.2711 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 7s 433ms/step - loss: 1.3328e-07 - accuracy: 1.0000 - val_loss: 4.2720 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 1.0348e-07 - accuracy: 1.0000 - val_loss: 4.2736 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 9.6858e-08 - accuracy: 1.0000 - val_loss: 4.2757 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 6s 424ms/step - loss: 2.3428e-07 - accuracy: 1.0000 - val_loss: 4.2781 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 1.0265e-07 - accuracy: 1.0000 - val_loss: 4.2791 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 9.2718e-08 - accuracy: 1.0000 - val_loss: 4.2778 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 1.2583e-07 - accuracy: 1.0000 - val_loss: 4.2790 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 4.2811 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 4.2841 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 1.0348e-07 - accuracy: 1.0000 - val_loss: 4.2863 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 4.2889 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 7.9473e-08 - accuracy: 1.0000 - val_loss: 4.2904 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 1.2004e-07 - accuracy: 1.0000 - val_loss: 4.2918 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 1.3163e-07 - accuracy: 1.0000 - val_loss: 4.2936 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 1.1176e-07 - accuracy: 1.0000 - val_loss: 4.2948 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 6s 424ms/step - loss: 8.4440e-08 - accuracy: 1.0000 - val_loss: 4.2964 - val_accuracy: 0.6757 - lr: 1.0000e-05\n",
      "lr changed to 1.0000000656873453e-06\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 6s 426ms/step - loss: 1.0845e-07 - accuracy: 1.0000 - val_loss: 4.2966 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 1.7467e-07 - accuracy: 1.0000 - val_loss: 4.2967 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 7s 437ms/step - loss: 1.0265e-07 - accuracy: 1.0000 - val_loss: 4.2968 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 1.0182e-07 - accuracy: 1.0000 - val_loss: 4.2970 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 1.5150e-07 - accuracy: 1.0000 - val_loss: 4.2970 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 8.6923e-08 - accuracy: 1.0000 - val_loss: 4.2972 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 7s 437ms/step - loss: 1.4736e-07 - accuracy: 1.0000 - val_loss: 4.2973 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 5s 338ms/step - loss: 1.5646e-07 - accuracy: 1.0000 - val_loss: 4.2973 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 6.9539e-08 - accuracy: 1.0000 - val_loss: 4.2974 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 7s 435ms/step - loss: 2.7401e-07 - accuracy: 1.0000 - val_loss: 4.2977 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 7s 459ms/step - loss: 1.0017e-07 - accuracy: 1.0000 - val_loss: 4.2978 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 4.2977 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 5.7949e-08 - accuracy: 1.0000 - val_loss: 4.2977 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 8.2784e-08 - accuracy: 1.0000 - val_loss: 4.2978 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 9.3546e-08 - accuracy: 1.0000 - val_loss: 4.2979 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 1.4404e-07 - accuracy: 1.0000 - val_loss: 4.2980 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 6s 438ms/step - loss: 8.7751e-08 - accuracy: 1.0000 - val_loss: 4.2980 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 1.0679e-07 - accuracy: 1.0000 - val_loss: 4.2982 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 6s 420ms/step - loss: 6.4572e-08 - accuracy: 1.0000 - val_loss: 4.2984 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 8.0301e-08 - accuracy: 1.0000 - val_loss: 4.2985 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 6s 420ms/step - loss: 6.3744e-08 - accuracy: 1.0000 - val_loss: 4.2987 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 8.6923e-08 - accuracy: 1.0000 - val_loss: 4.2988 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 7s 462ms/step - loss: 1.1838e-07 - accuracy: 1.0000 - val_loss: 4.2989 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 1.0100e-07 - accuracy: 1.0000 - val_loss: 4.2991 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 7s 497ms/step - loss: 2.5249e-07 - accuracy: 1.0000 - val_loss: 4.2995 - val_accuracy: 0.6757 - lr: 1.0000e-06\n",
      "\n",
      "2 of kfold 5\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 19s 607ms/step - loss: 0.7455 - accuracy: 0.4345 - val_loss: 0.6825 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 0.6350 - accuracy: 0.6138 - val_loss: 0.6583 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 7s 434ms/step - loss: 0.4376 - accuracy: 0.8414 - val_loss: 0.8271 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 0.2837 - accuracy: 0.8828 - val_loss: 0.8971 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 7s 462ms/step - loss: 0.0997 - accuracy: 0.9793 - val_loss: 1.1696 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 7s 438ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5973 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.7152 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1749 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 6s 411ms/step - loss: 0.2254 - accuracy: 0.9724 - val_loss: 1.8612 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0270 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3026 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 7s 440ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.4511 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 7.7970e-04 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 4.8645e-04 - accuracy: 1.0000 - val_loss: 2.8564 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 7s 477ms/step - loss: 4.4478e-04 - accuracy: 1.0000 - val_loss: 3.1319 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 8s 526ms/step - loss: 2.0706e-04 - accuracy: 1.0000 - val_loss: 3.2781 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 7s 443ms/step - loss: 1.1890e-04 - accuracy: 1.0000 - val_loss: 3.5241 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 7.2263e-05 - accuracy: 1.0000 - val_loss: 3.8880 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 3.3314e-05 - accuracy: 1.0000 - val_loss: 3.9978 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 2.1556e-05 - accuracy: 1.0000 - val_loss: 4.1520 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 7s 438ms/step - loss: 1.0580e-05 - accuracy: 1.0000 - val_loss: 4.0667 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 7s 463ms/step - loss: 6.1972e-06 - accuracy: 1.0000 - val_loss: 4.2319 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 6.3483e-06 - accuracy: 1.0000 - val_loss: 4.3280 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 3.1109e-06 - accuracy: 1.0000 - val_loss: 5.0107 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 7s 470ms/step - loss: 0.8345 - accuracy: 0.9172 - val_loss: 3.8506 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "lr changed to 0.00010000000474974513\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 0.2121 - accuracy: 0.9793 - val_loss: 3.9108 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 2.8497e-05 - accuracy: 1.0000 - val_loss: 3.9113 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 7s 485ms/step - loss: 2.5194e-04 - accuracy: 1.0000 - val_loss: 3.9311 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 7s 485ms/step - loss: 3.5459e-05 - accuracy: 1.0000 - val_loss: 3.9335 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 5.1164e-05 - accuracy: 1.0000 - val_loss: 3.9435 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 2.0718e-05 - accuracy: 1.0000 - val_loss: 3.9507 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 3.4399e-05 - accuracy: 1.0000 - val_loss: 3.9761 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 7s 463ms/step - loss: 1.7700e-05 - accuracy: 1.0000 - val_loss: 3.9950 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 7s 481ms/step - loss: 2.4772e-05 - accuracy: 1.0000 - val_loss: 4.0522 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 7s 473ms/step - loss: 2.0863e-05 - accuracy: 1.0000 - val_loss: 4.1276 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 1.2921e-05 - accuracy: 1.0000 - val_loss: 4.1880 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 7s 469ms/step - loss: 9.3966e-06 - accuracy: 1.0000 - val_loss: 4.2878 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 7s 470ms/step - loss: 8.3954e-06 - accuracy: 1.0000 - val_loss: 4.3944 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 7s 462ms/step - loss: 6.4183e-06 - accuracy: 1.0000 - val_loss: 4.5222 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 5.8968e-06 - accuracy: 1.0000 - val_loss: 4.4906 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 7s 493ms/step - loss: 3.4743e-06 - accuracy: 1.0000 - val_loss: 4.6173 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 7s 494ms/step - loss: 3.6140e-06 - accuracy: 1.0000 - val_loss: 4.6910 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 2.2699e-06 - accuracy: 1.0000 - val_loss: 4.6922 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 2.8577e-06 - accuracy: 1.0000 - val_loss: 4.6524 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 9s 581ms/step - loss: 2.9259e-06 - accuracy: 1.0000 - val_loss: 4.6981 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 9s 572ms/step - loss: 1.8745e-06 - accuracy: 1.0000 - val_loss: 4.6768 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 8s 563ms/step - loss: 2.0627e-06 - accuracy: 1.0000 - val_loss: 4.6289 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 2.0471e-06 - accuracy: 1.0000 - val_loss: 4.7545 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 8s 513ms/step - loss: 1.0014e-06 - accuracy: 1.0000 - val_loss: 4.7460 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 7s 480ms/step - loss: 1.5834e-06 - accuracy: 1.0000 - val_loss: 4.7612 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "lr changed to 1.0000000474974514e-05\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 9.7998e-07 - accuracy: 1.0000 - val_loss: 4.7664 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 9.3148e-07 - accuracy: 1.0000 - val_loss: 4.7673 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 8s 561ms/step - loss: 1.3680e-06 - accuracy: 1.0000 - val_loss: 4.7788 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 1.6147e-06 - accuracy: 1.0000 - val_loss: 4.7794 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 7s 491ms/step - loss: 1.3853e-06 - accuracy: 1.0000 - val_loss: 4.7871 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 8s 521ms/step - loss: 1.1058e-06 - accuracy: 1.0000 - val_loss: 4.7875 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 9s 629ms/step - loss: 1.2381e-06 - accuracy: 1.0000 - val_loss: 4.7923 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 11s 730ms/step - loss: 1.7108e-06 - accuracy: 1.0000 - val_loss: 4.7854 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 9s 564ms/step - loss: 1.6500e-06 - accuracy: 1.0000 - val_loss: 4.7772 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.4297e-06 - accuracy: 1.0000 - val_loss: 4.7791 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 8s 517ms/step - loss: 1.1247e-06 - accuracy: 1.0000 - val_loss: 4.7835 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 8s 514ms/step - loss: 1.1370e-06 - accuracy: 1.0000 - val_loss: 4.7885 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 8s 506ms/step - loss: 1.2225e-06 - accuracy: 1.0000 - val_loss: 4.8001 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 1.3220e-06 - accuracy: 1.0000 - val_loss: 4.8064 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 8s 523ms/step - loss: 9.4298e-07 - accuracy: 1.0000 - val_loss: 4.8069 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 1.7782e-06 - accuracy: 1.0000 - val_loss: 4.7993 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 1.3401e-06 - accuracy: 1.0000 - val_loss: 4.8093 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 7s 500ms/step - loss: 1.0704e-06 - accuracy: 1.0000 - val_loss: 4.8098 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 7s 484ms/step - loss: 1.9213e-06 - accuracy: 1.0000 - val_loss: 4.8134 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 7s 493ms/step - loss: 1.2825e-06 - accuracy: 1.0000 - val_loss: 4.8195 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 7s 488ms/step - loss: 1.2661e-06 - accuracy: 1.0000 - val_loss: 4.8203 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 7s 495ms/step - loss: 8.0158e-07 - accuracy: 1.0000 - val_loss: 4.8188 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 8s 535ms/step - loss: 1.4182e-06 - accuracy: 1.0000 - val_loss: 4.8250 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 9s 599ms/step - loss: 1.3064e-06 - accuracy: 1.0000 - val_loss: 4.8299 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 8s 557ms/step - loss: 1.2398e-06 - accuracy: 1.0000 - val_loss: 4.8292 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "lr changed to 1.0000000656873453e-06\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 7s 489ms/step - loss: 1.7034e-06 - accuracy: 1.0000 - val_loss: 4.8302 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 8s 510ms/step - loss: 1.7544e-06 - accuracy: 1.0000 - val_loss: 4.8299 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 8s 544ms/step - loss: 1.1502e-06 - accuracy: 1.0000 - val_loss: 4.8302 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 9s 579ms/step - loss: 9.1010e-07 - accuracy: 1.0000 - val_loss: 4.8307 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 7s 471ms/step - loss: 9.7176e-07 - accuracy: 1.0000 - val_loss: 4.8312 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 8s 538ms/step - loss: 9.5532e-07 - accuracy: 1.0000 - val_loss: 4.8315 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 8s 543ms/step - loss: 1.0762e-06 - accuracy: 1.0000 - val_loss: 4.8318 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 8s 554ms/step - loss: 9.9149e-07 - accuracy: 1.0000 - val_loss: 4.8324 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 8s 547ms/step - loss: 1.1576e-06 - accuracy: 1.0000 - val_loss: 4.8331 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 8s 576ms/step - loss: 1.8202e-06 - accuracy: 1.0000 - val_loss: 4.8342 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 9s 577ms/step - loss: 1.3014e-06 - accuracy: 1.0000 - val_loss: 4.8342 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 9s 587ms/step - loss: 1.1452e-06 - accuracy: 1.0000 - val_loss: 4.8337 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 9s 587ms/step - loss: 1.4050e-06 - accuracy: 1.0000 - val_loss: 4.8352 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 9s 617ms/step - loss: 2.0216e-06 - accuracy: 1.0000 - val_loss: 4.8337 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 10s 624ms/step - loss: 1.1017e-06 - accuracy: 1.0000 - val_loss: 4.8339 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 8s 548ms/step - loss: 1.5924e-06 - accuracy: 1.0000 - val_loss: 4.8356 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 1.2998e-06 - accuracy: 1.0000 - val_loss: 4.8359 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 9s 575ms/step - loss: 1.0515e-06 - accuracy: 1.0000 - val_loss: 4.8359 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 8s 547ms/step - loss: 9.1421e-07 - accuracy: 1.0000 - val_loss: 4.8355 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 8s 525ms/step - loss: 8.3857e-07 - accuracy: 1.0000 - val_loss: 4.8362 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 8s 507ms/step - loss: 1.1913e-06 - accuracy: 1.0000 - val_loss: 4.8367 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 9s 577ms/step - loss: 1.2587e-06 - accuracy: 1.0000 - val_loss: 4.8364 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 8s 524ms/step - loss: 1.0597e-06 - accuracy: 1.0000 - val_loss: 4.8368 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 9s 585ms/step - loss: 6.4209e-07 - accuracy: 1.0000 - val_loss: 4.8384 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 9s 578ms/step - loss: 9.5367e-07 - accuracy: 1.0000 - val_loss: 4.8395 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "\n",
      "3 of kfold 5\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 18s 786ms/step - loss: 0.7153 - accuracy: 0.5448 - val_loss: 0.6745 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 10s 646ms/step - loss: 0.6066 - accuracy: 0.7103 - val_loss: 0.7740 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 10s 660ms/step - loss: 0.4038 - accuracy: 0.8690 - val_loss: 1.0844 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 11s 772ms/step - loss: 0.1840 - accuracy: 0.9448 - val_loss: 1.3393 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 13s 852ms/step - loss: 0.0925 - accuracy: 0.9793 - val_loss: 1.1523 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 0.1061 - accuracy: 0.9793 - val_loss: 1.5876 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 1.4812 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 13s 847ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.7882 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0688 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 12s 761ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3157 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 11s 756ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 12s 793ms/step - loss: 5.4783e-04 - accuracy: 1.0000 - val_loss: 2.9649 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 11s 722ms/step - loss: 3.8676e-04 - accuracy: 1.0000 - val_loss: 3.2458 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 1.5114e-04 - accuracy: 1.0000 - val_loss: 3.5066 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 8.1694e-05 - accuracy: 1.0000 - val_loss: 4.2214 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 12s 775ms/step - loss: 4.4676e-05 - accuracy: 1.0000 - val_loss: 4.3588 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 12s 785ms/step - loss: 2.8584e-05 - accuracy: 1.0000 - val_loss: 4.6118 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 12s 828ms/step - loss: 2.1936e-05 - accuracy: 1.0000 - val_loss: 4.8886 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 9.2266e-06 - accuracy: 1.0000 - val_loss: 4.8643 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 0.6175 - accuracy: 0.9172 - val_loss: 4.1506 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 12s 791ms/step - loss: 5.2281e-04 - accuracy: 1.0000 - val_loss: 4.2419 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 12s 796ms/step - loss: 5.9416e-04 - accuracy: 1.0000 - val_loss: 4.6549 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 12s 802ms/step - loss: 2.4130e-05 - accuracy: 1.0000 - val_loss: 4.6643 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 12s 810ms/step - loss: 2.5005e-05 - accuracy: 1.0000 - val_loss: 4.6764 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 12s 802ms/step - loss: 2.7080e-05 - accuracy: 1.0000 - val_loss: 4.7175 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "lr changed to 0.00010000000474974513\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 12s 789ms/step - loss: 4.7679e-05 - accuracy: 1.0000 - val_loss: 4.7111 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.4818e-05 - accuracy: 1.0000 - val_loss: 4.7150 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 13s 837ms/step - loss: 2.3122e-05 - accuracy: 1.0000 - val_loss: 4.7531 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 2.1112e-05 - accuracy: 1.0000 - val_loss: 4.7922 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 12s 822ms/step - loss: 2.0921e-05 - accuracy: 1.0000 - val_loss: 4.8454 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 1.9166e-05 - accuracy: 1.0000 - val_loss: 4.8745 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 11s 762ms/step - loss: 1.8087e-05 - accuracy: 1.0000 - val_loss: 5.0316 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 13s 908ms/step - loss: 1.5905e-05 - accuracy: 1.0000 - val_loss: 5.4254 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 12s 792ms/step - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 5.5118 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 11s 748ms/step - loss: 8.8221e-06 - accuracy: 1.0000 - val_loss: 5.6405 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 13s 852ms/step - loss: 6.6452e-06 - accuracy: 1.0000 - val_loss: 5.7542 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 12s 834ms/step - loss: 7.5084e-06 - accuracy: 1.0000 - val_loss: 5.7485 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 12s 785ms/step - loss: 6.7628e-06 - accuracy: 1.0000 - val_loss: 5.8315 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 7.7969e-06 - accuracy: 1.0000 - val_loss: 6.0270 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 4.7642e-06 - accuracy: 1.0000 - val_loss: 5.7505 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 12s 808ms/step - loss: 6.3878e-06 - accuracy: 1.0000 - val_loss: 5.8783 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 12s 798ms/step - loss: 6.8497e-06 - accuracy: 1.0000 - val_loss: 6.2879 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 12s 800ms/step - loss: 7.0595e-06 - accuracy: 1.0000 - val_loss: 6.2903 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 4.8078e-06 - accuracy: 1.0000 - val_loss: 6.3670 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 12s 805ms/step - loss: 3.7127e-06 - accuracy: 1.0000 - val_loss: 6.3852 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 12s 820ms/step - loss: 3.9215e-06 - accuracy: 1.0000 - val_loss: 6.4480 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 12s 806ms/step - loss: 3.2910e-06 - accuracy: 1.0000 - val_loss: 6.5027 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 3.9117e-06 - accuracy: 1.0000 - val_loss: 6.5654 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 12s 810ms/step - loss: 2.9128e-06 - accuracy: 1.0000 - val_loss: 6.5672 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 2.8215e-06 - accuracy: 1.0000 - val_loss: 6.5858 - val_accuracy: 0.4722 - lr: 1.0000e-04\n",
      "lr changed to 1.0000000474974514e-05\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 12s 820ms/step - loss: 3.4274e-06 - accuracy: 1.0000 - val_loss: 6.5845 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 12s 799ms/step - loss: 3.0526e-06 - accuracy: 1.0000 - val_loss: 6.5802 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 12s 800ms/step - loss: 1.8950e-06 - accuracy: 1.0000 - val_loss: 6.5845 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 12s 814ms/step - loss: 2.9539e-06 - accuracy: 1.0000 - val_loss: 6.5962 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 12s 791ms/step - loss: 2.1852e-06 - accuracy: 1.0000 - val_loss: 6.6019 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 12s 793ms/step - loss: 4.8661e-06 - accuracy: 1.0000 - val_loss: 6.6273 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 12s 806ms/step - loss: 1.9443e-06 - accuracy: 1.0000 - val_loss: 6.6331 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 12s 793ms/step - loss: 2.6333e-06 - accuracy: 1.0000 - val_loss: 6.6377 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 12s 838ms/step - loss: 3.1874e-06 - accuracy: 1.0000 - val_loss: 6.6398 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 13s 852ms/step - loss: 2.4179e-06 - accuracy: 1.0000 - val_loss: 6.6445 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 11s 747ms/step - loss: 3.1726e-06 - accuracy: 1.0000 - val_loss: 6.6543 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 12s 796ms/step - loss: 2.2181e-06 - accuracy: 1.0000 - val_loss: 6.6589 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 12s 774ms/step - loss: 2.8536e-06 - accuracy: 1.0000 - val_loss: 6.6651 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 12s 772ms/step - loss: 3.2712e-06 - accuracy: 1.0000 - val_loss: 6.6730 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 12s 818ms/step - loss: 2.4894e-06 - accuracy: 1.0000 - val_loss: 6.6777 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 12s 783ms/step - loss: 3.0673e-06 - accuracy: 1.0000 - val_loss: 6.6730 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 12s 794ms/step - loss: 3.4480e-06 - accuracy: 1.0000 - val_loss: 6.6807 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 12s 828ms/step - loss: 2.1301e-06 - accuracy: 1.0000 - val_loss: 6.6874 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 11s 738ms/step - loss: 2.7656e-06 - accuracy: 1.0000 - val_loss: 6.6934 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 12s 787ms/step - loss: 2.4771e-06 - accuracy: 1.0000 - val_loss: 6.6995 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 13s 907ms/step - loss: 3.2046e-06 - accuracy: 1.0000 - val_loss: 6.7038 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 2.0578e-06 - accuracy: 1.0000 - val_loss: 6.7093 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 12s 768ms/step - loss: 1.9008e-06 - accuracy: 1.0000 - val_loss: 6.7107 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 12s 789ms/step - loss: 3.2153e-06 - accuracy: 1.0000 - val_loss: 6.7113 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 12s 828ms/step - loss: 2.5354e-06 - accuracy: 1.0000 - val_loss: 6.7130 - val_accuracy: 0.4722 - lr: 1.0000e-05\n",
      "lr changed to 1.0000000656873453e-06\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 12s 818ms/step - loss: 2.3908e-06 - accuracy: 1.0000 - val_loss: 6.7140 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 2.4442e-06 - accuracy: 1.0000 - val_loss: 6.7148 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 12s 808ms/step - loss: 2.5223e-06 - accuracy: 1.0000 - val_loss: 6.7147 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 12s 801ms/step - loss: 2.6168e-06 - accuracy: 1.0000 - val_loss: 6.7152 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 13s 847ms/step - loss: 1.4124e-06 - accuracy: 1.0000 - val_loss: 6.7156 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 12s 805ms/step - loss: 1.8868e-06 - accuracy: 1.0000 - val_loss: 6.7165 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 12s 834ms/step - loss: 2.7278e-06 - accuracy: 1.0000 - val_loss: 6.7185 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 3.7003e-06 - accuracy: 1.0000 - val_loss: 6.7199 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 12s 791ms/step - loss: 3.4348e-06 - accuracy: 1.0000 - val_loss: 6.7200 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 8s 526ms/step - loss: 2.1647e-06 - accuracy: 1.0000 - val_loss: 6.7198 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 7s 484ms/step - loss: 2.8429e-06 - accuracy: 1.0000 - val_loss: 6.7201 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 6s 420ms/step - loss: 2.6102e-06 - accuracy: 1.0000 - val_loss: 6.7210 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 7s 473ms/step - loss: 1.6993e-06 - accuracy: 1.0000 - val_loss: 6.7214 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 6s 438ms/step - loss: 2.0496e-06 - accuracy: 1.0000 - val_loss: 6.7219 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 2.7796e-06 - accuracy: 1.0000 - val_loss: 6.7224 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 7s 457ms/step - loss: 3.2490e-06 - accuracy: 1.0000 - val_loss: 6.7224 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 3.4602e-06 - accuracy: 1.0000 - val_loss: 6.7235 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 6s 400ms/step - loss: 2.6152e-06 - accuracy: 1.0000 - val_loss: 6.7240 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 2.9777e-06 - accuracy: 1.0000 - val_loss: 6.7239 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 2.8741e-06 - accuracy: 1.0000 - val_loss: 6.7247 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 6s 404ms/step - loss: 2.4343e-06 - accuracy: 1.0000 - val_loss: 6.7251 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 2.9366e-06 - accuracy: 1.0000 - val_loss: 6.7258 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 399ms/step - loss: 2.7944e-06 - accuracy: 1.0000 - val_loss: 6.7260 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 3.0616e-06 - accuracy: 1.0000 - val_loss: 6.7270 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 6s 397ms/step - loss: 1.7659e-06 - accuracy: 1.0000 - val_loss: 6.7277 - val_accuracy: 0.4722 - lr: 1.0000e-06\n",
      "\n",
      "4 of kfold 5\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 14s 485ms/step - loss: 0.7178 - accuracy: 0.4897 - val_loss: 0.6864 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 6s 387ms/step - loss: 0.6439 - accuracy: 0.6207 - val_loss: 0.6864 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 6s 396ms/step - loss: 0.4522 - accuracy: 0.8345 - val_loss: 0.7805 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 6s 376ms/step - loss: 0.2389 - accuracy: 0.9103 - val_loss: 1.1385 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 358ms/step - loss: 0.1103 - accuracy: 0.9655 - val_loss: 1.2703 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 7s 465ms/step - loss: 0.0492 - accuracy: 0.9862 - val_loss: 1.8143 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 6s 410ms/step - loss: 0.1362 - accuracy: 0.9586 - val_loss: 1.1561 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 6s 428ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3042 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 356ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7459 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 7s 468ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0450 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 7s 467ms/step - loss: 9.3386e-04 - accuracy: 1.0000 - val_loss: 2.3005 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 7s 442ms/step - loss: 5.2128e-04 - accuracy: 1.0000 - val_loss: 2.6674 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 354ms/step - loss: 2.2460e-04 - accuracy: 1.0000 - val_loss: 2.9988 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 6s 395ms/step - loss: 1.1611e-04 - accuracy: 1.0000 - val_loss: 3.1188 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 8.9818e-05 - accuracy: 1.0000 - val_loss: 3.2026 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 4.1320e-05 - accuracy: 1.0000 - val_loss: 3.9774 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 2.2864e-05 - accuracy: 1.0000 - val_loss: 3.8479 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 1.2838e-05 - accuracy: 1.0000 - val_loss: 4.1882 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 9.2553e-06 - accuracy: 1.0000 - val_loss: 4.3444 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 4.7683e-06 - accuracy: 1.0000 - val_loss: 4.5733 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 3.6461e-06 - accuracy: 1.0000 - val_loss: 4.9179 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 1.8958e-06 - accuracy: 1.0000 - val_loss: 4.9688 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 1.7281e-06 - accuracy: 1.0000 - val_loss: 5.2549 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 6s 405ms/step - loss: 1.0211e-06 - accuracy: 1.0000 - val_loss: 5.2803 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "lr changed to 0.00010000000474974513\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 8.8872e-07 - accuracy: 1.0000 - val_loss: 5.2783 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 6s 420ms/step - loss: 6.5277e-07 - accuracy: 1.0000 - val_loss: 5.3030 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 6s 387ms/step - loss: 8.3611e-07 - accuracy: 1.0000 - val_loss: 5.3214 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 4.2669e-07 - accuracy: 1.0000 - val_loss: 5.3373 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 5.6974e-07 - accuracy: 1.0000 - val_loss: 5.3765 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 8.7721e-07 - accuracy: 1.0000 - val_loss: 5.4120 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 5.0561e-07 - accuracy: 1.0000 - val_loss: 5.4092 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 6s 406ms/step - loss: 4.9163e-07 - accuracy: 1.0000 - val_loss: 5.4260 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 6s 401ms/step - loss: 7.4732e-07 - accuracy: 1.0000 - val_loss: 5.4369 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 4.4477e-07 - accuracy: 1.0000 - val_loss: 5.4520 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 7s 464ms/step - loss: 4.0120e-07 - accuracy: 1.0000 - val_loss: 5.4556 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 4.6039e-07 - accuracy: 1.0000 - val_loss: 5.4726 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 6s 405ms/step - loss: 4.9410e-07 - accuracy: 1.0000 - val_loss: 5.4984 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 6s 395ms/step - loss: 3.8229e-07 - accuracy: 1.0000 - val_loss: 5.5187 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 3.7818e-07 - accuracy: 1.0000 - val_loss: 5.5429 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 2.9103e-07 - accuracy: 1.0000 - val_loss: 5.5571 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 3.6092e-07 - accuracy: 1.0000 - val_loss: 5.5698 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 6s 411ms/step - loss: 5.2781e-07 - accuracy: 1.0000 - val_loss: 5.5579 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 5.0561e-07 - accuracy: 1.0000 - val_loss: 5.5765 - val_accuracy: 0.5278 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 2.4088e-07 - accuracy: 1.0000 - val_loss: 5.5888 - val_accuracy: 0.5278 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 3.2474e-07 - accuracy: 1.0000 - val_loss: 5.6360 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 3.0090e-07 - accuracy: 1.0000 - val_loss: 5.6500 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 411ms/step - loss: 2.8446e-07 - accuracy: 1.0000 - val_loss: 5.6864 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 5.7009 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 6s 391ms/step - loss: 2.2444e-07 - accuracy: 1.0000 - val_loss: 5.7244 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
      "lr changed to 1.0000000474974514e-05\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 6s 389ms/step - loss: 2.4746e-07 - accuracy: 1.0000 - val_loss: 5.7257 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 6s 399ms/step - loss: 2.4335e-07 - accuracy: 1.0000 - val_loss: 5.7277 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 6s 410ms/step - loss: 1.8827e-07 - accuracy: 1.0000 - val_loss: 5.7295 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 6s 419ms/step - loss: 2.3595e-07 - accuracy: 1.0000 - val_loss: 5.7312 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 2.6802e-07 - accuracy: 1.0000 - val_loss: 5.7313 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 6s 404ms/step - loss: 1.9073e-07 - accuracy: 1.0000 - val_loss: 5.7326 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 6s 409ms/step - loss: 2.5568e-07 - accuracy: 1.0000 - val_loss: 5.7337 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 6s 406ms/step - loss: 2.6308e-07 - accuracy: 1.0000 - val_loss: 5.7356 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 5s 366ms/step - loss: 2.2855e-07 - accuracy: 1.0000 - val_loss: 5.7371 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 2.4417e-07 - accuracy: 1.0000 - val_loss: 5.7385 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 6s 402ms/step - loss: 2.0060e-07 - accuracy: 1.0000 - val_loss: 5.7401 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 6s 397ms/step - loss: 2.1129e-07 - accuracy: 1.0000 - val_loss: 5.7414 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 6s 379ms/step - loss: 2.2444e-07 - accuracy: 1.0000 - val_loss: 5.7431 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 2.4828e-07 - accuracy: 1.0000 - val_loss: 5.7440 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 6s 433ms/step - loss: 1.5785e-07 - accuracy: 1.0000 - val_loss: 5.7454 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 6s 431ms/step - loss: 1.6360e-07 - accuracy: 1.0000 - val_loss: 5.7474 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 1.5127e-07 - accuracy: 1.0000 - val_loss: 5.7489 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 2.1293e-07 - accuracy: 1.0000 - val_loss: 5.7499 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 6s 376ms/step - loss: 2.4253e-07 - accuracy: 1.0000 - val_loss: 5.7504 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 3.6009e-07 - accuracy: 1.0000 - val_loss: 5.7524 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 7s 434ms/step - loss: 1.4881e-07 - accuracy: 1.0000 - val_loss: 5.7540 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 1.6936e-07 - accuracy: 1.0000 - val_loss: 5.7553 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 1.8580e-07 - accuracy: 1.0000 - val_loss: 5.7568 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 1.6607e-07 - accuracy: 1.0000 - val_loss: 5.7585 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 1.9896e-07 - accuracy: 1.0000 - val_loss: 5.7604 - val_accuracy: 0.5556 - lr: 1.0000e-05\n",
      "lr changed to 1.0000000656873453e-06\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 2.5979e-07 - accuracy: 1.0000 - val_loss: 5.7606 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 2.5897e-07 - accuracy: 1.0000 - val_loss: 5.7608 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 2.5651e-07 - accuracy: 1.0000 - val_loss: 5.7609 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 6s 396ms/step - loss: 1.8334e-07 - accuracy: 1.0000 - val_loss: 5.7610 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 6s 416ms/step - loss: 1.8416e-07 - accuracy: 1.0000 - val_loss: 5.7612 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 2.1293e-07 - accuracy: 1.0000 - val_loss: 5.7614 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 2.0471e-07 - accuracy: 1.0000 - val_loss: 5.7615 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 2.3431e-07 - accuracy: 1.0000 - val_loss: 5.7615 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 6s 418ms/step - loss: 1.5785e-07 - accuracy: 1.0000 - val_loss: 5.7617 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 1.5209e-07 - accuracy: 1.0000 - val_loss: 5.7619 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 5.7621 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 2.6884e-07 - accuracy: 1.0000 - val_loss: 5.7623 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 6s 399ms/step - loss: 1.4470e-07 - accuracy: 1.0000 - val_loss: 5.7624 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 6s 383ms/step - loss: 1.6114e-07 - accuracy: 1.0000 - val_loss: 5.7627 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 6s 411ms/step - loss: 1.5209e-07 - accuracy: 1.0000 - val_loss: 5.7629 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 3.2967e-07 - accuracy: 1.0000 - val_loss: 5.7630 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 6s 389ms/step - loss: 1.7922e-07 - accuracy: 1.0000 - val_loss: 5.7631 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 6s 427ms/step - loss: 3.7407e-07 - accuracy: 1.0000 - val_loss: 5.7633 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 2.6884e-07 - accuracy: 1.0000 - val_loss: 5.7635 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 2.4582e-07 - accuracy: 1.0000 - val_loss: 5.7635 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 6s 395ms/step - loss: 1.6196e-07 - accuracy: 1.0000 - val_loss: 5.7635 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 418ms/step - loss: 1.9485e-07 - accuracy: 1.0000 - val_loss: 5.7637 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 3.0008e-07 - accuracy: 1.0000 - val_loss: 5.7633 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 6s 419ms/step - loss: 2.4171e-07 - accuracy: 1.0000 - val_loss: 5.7635 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 6s 408ms/step - loss: 2.6555e-07 - accuracy: 1.0000 - val_loss: 5.7637 - val_accuracy: 0.5556 - lr: 1.0000e-06\n",
      "\n",
      "5 of kfold 5\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 17s 644ms/step - loss: 0.7174 - accuracy: 0.5241 - val_loss: 0.7266 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 0.5856 - accuracy: 0.7034 - val_loss: 0.7746 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 8s 540ms/step - loss: 0.4266 - accuracy: 0.8276 - val_loss: 1.0142 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 8s 531ms/step - loss: 0.2054 - accuracy: 0.9379 - val_loss: 1.2492 - val_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 8s 541ms/step - loss: 0.0895 - accuracy: 0.9793 - val_loss: 1.3622 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 8s 531ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.7119 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 8s 533ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.9723 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 8s 508ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2869 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 8s 518ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5152 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 7.3273e-04 - accuracy: 1.0000 - val_loss: 2.9051 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 3.7582e-04 - accuracy: 1.0000 - val_loss: 3.8381 - val_accuracy: 0.4722 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 7s 481ms/step - loss: 1.8529e-04 - accuracy: 1.0000 - val_loss: 3.4894 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 9s 611ms/step - loss: 1.1723e-04 - accuracy: 1.0000 - val_loss: 3.8177 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 9s 578ms/step - loss: 0.5691 - accuracy: 0.9241 - val_loss: 3.0986 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 0.0180 - accuracy: 0.9931 - val_loss: 2.8812 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 8s 540ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0669 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.3197 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 8s 564ms/step - loss: 5.8033e-04 - accuracy: 1.0000 - val_loss: 3.1566 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 1.4712e-04 - accuracy: 1.0000 - val_loss: 3.1999 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 1.4349e-04 - accuracy: 1.0000 - val_loss: 3.3406 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 9s 603ms/step - loss: 1.2016e-04 - accuracy: 1.0000 - val_loss: 3.4683 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 8s 558ms/step - loss: 8.0563e-05 - accuracy: 1.0000 - val_loss: 3.6588 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 8s 552ms/step - loss: 4.1417e-05 - accuracy: 1.0000 - val_loss: 3.9210 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 8s 559ms/step - loss: 3.9454e-05 - accuracy: 1.0000 - val_loss: 4.2352 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 2.1559e-05 - accuracy: 1.0000 - val_loss: 4.5136 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "lr changed to 0.00010000000474974513\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 8s 555ms/step - loss: 1.0647e-05 - accuracy: 1.0000 - val_loss: 4.5474 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 8s 544ms/step - loss: 1.7028e-05 - accuracy: 1.0000 - val_loss: 4.5932 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 1.1285e-05 - accuracy: 1.0000 - val_loss: 4.6340 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 8s 541ms/step - loss: 1.1714e-05 - accuracy: 1.0000 - val_loss: 4.6628 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 8s 548ms/step - loss: 2.0759e-05 - accuracy: 1.0000 - val_loss: 4.7219 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 8s 548ms/step - loss: 8.4489e-06 - accuracy: 1.0000 - val_loss: 4.7529 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 8s 563ms/step - loss: 5.6003e-06 - accuracy: 1.0000 - val_loss: 4.7714 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 7.8455e-06 - accuracy: 1.0000 - val_loss: 4.7635 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 8s 555ms/step - loss: 9.2449e-06 - accuracy: 1.0000 - val_loss: 4.8783 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 8s 565ms/step - loss: 4.6968e-06 - accuracy: 1.0000 - val_loss: 4.7940 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 6.6180e-06 - accuracy: 1.0000 - val_loss: 4.8529 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 9s 573ms/step - loss: 5.2870e-06 - accuracy: 1.0000 - val_loss: 4.6545 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 8s 567ms/step - loss: 5.1226e-06 - accuracy: 1.0000 - val_loss: 4.6160 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 8s 567ms/step - loss: 5.0996e-06 - accuracy: 1.0000 - val_loss: 4.7571 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 9s 596ms/step - loss: 3.6017e-06 - accuracy: 1.0000 - val_loss: 4.8828 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 8s 525ms/step - loss: 3.0493e-06 - accuracy: 1.0000 - val_loss: 4.7243 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 8s 533ms/step - loss: 3.9043e-06 - accuracy: 1.0000 - val_loss: 5.0737 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 8s 551ms/step - loss: 3.2326e-06 - accuracy: 1.0000 - val_loss: 5.1733 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 9s 585ms/step - loss: 2.9909e-06 - accuracy: 1.0000 - val_loss: 5.2054 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 9s 575ms/step - loss: 2.1507e-06 - accuracy: 1.0000 - val_loss: 5.2252 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 9s 573ms/step - loss: 2.5009e-06 - accuracy: 1.0000 - val_loss: 5.2411 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 8s 555ms/step - loss: 5.6270e-06 - accuracy: 1.0000 - val_loss: 5.2971 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 8s 555ms/step - loss: 3.0221e-06 - accuracy: 1.0000 - val_loss: 5.3088 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 8s 552ms/step - loss: 3.1405e-06 - accuracy: 1.0000 - val_loss: 5.3222 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 8s 537ms/step - loss: 2.3167e-06 - accuracy: 1.0000 - val_loss: 5.3114 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "lr changed to 1.0000000474974514e-05\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 7s 497ms/step - loss: 3.0830e-06 - accuracy: 1.0000 - val_loss: 5.3249 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 9s 595ms/step - loss: 2.2609e-06 - accuracy: 1.0000 - val_loss: 5.3328 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 8s 530ms/step - loss: 2.6998e-06 - accuracy: 1.0000 - val_loss: 5.3294 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 8s 553ms/step - loss: 1.6936e-06 - accuracy: 1.0000 - val_loss: 5.3271 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 9s 632ms/step - loss: 2.2280e-06 - accuracy: 1.0000 - val_loss: 5.3315 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 8s 504ms/step - loss: 3.9872e-06 - accuracy: 1.0000 - val_loss: 5.3187 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 7s 499ms/step - loss: 1.4412e-06 - accuracy: 1.0000 - val_loss: 5.3201 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 8s 544ms/step - loss: 2.0824e-06 - accuracy: 1.0000 - val_loss: 5.3252 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 8s 551ms/step - loss: 2.2140e-06 - accuracy: 1.0000 - val_loss: 5.3368 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 8s 564ms/step - loss: 1.4626e-06 - accuracy: 1.0000 - val_loss: 5.3434 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 8s 544ms/step - loss: 2.5123e-06 - accuracy: 1.0000 - val_loss: 5.3392 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 8s 530ms/step - loss: 3.0154e-06 - accuracy: 1.0000 - val_loss: 5.3497 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 8s 563ms/step - loss: 1.8810e-06 - accuracy: 1.0000 - val_loss: 5.3536 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 9s 606ms/step - loss: 2.6086e-06 - accuracy: 1.0000 - val_loss: 5.3570 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 9s 580ms/step - loss: 1.2316e-06 - accuracy: 1.0000 - val_loss: 5.3566 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 9s 569ms/step - loss: 1.4691e-06 - accuracy: 1.0000 - val_loss: 5.3630 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 8s 532ms/step - loss: 1.8876e-06 - accuracy: 1.0000 - val_loss: 5.3516 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 8s 563ms/step - loss: 1.6443e-06 - accuracy: 1.0000 - val_loss: 5.3586 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 8s 559ms/step - loss: 1.4560e-06 - accuracy: 1.0000 - val_loss: 5.3553 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 9s 583ms/step - loss: 2.2115e-06 - accuracy: 1.0000 - val_loss: 5.3581 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 9s 576ms/step - loss: 1.7643e-06 - accuracy: 1.0000 - val_loss: 5.3641 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 9s 591ms/step - loss: 1.3023e-06 - accuracy: 1.0000 - val_loss: 5.3767 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 8s 567ms/step - loss: 1.4979e-06 - accuracy: 1.0000 - val_loss: 5.3812 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 9s 573ms/step - loss: 1.7643e-06 - accuracy: 1.0000 - val_loss: 5.3793 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 9s 625ms/step - loss: 1.7857e-06 - accuracy: 1.0000 - val_loss: 5.3838 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "lr changed to 1.0000000656873453e-06\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 7s 487ms/step - loss: 2.3282e-06 - accuracy: 1.0000 - val_loss: 5.3842 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 9s 588ms/step - loss: 1.9328e-06 - accuracy: 1.0000 - val_loss: 5.3845 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 8s 540ms/step - loss: 2.3521e-06 - accuracy: 1.0000 - val_loss: 5.3844 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 8s 561ms/step - loss: 2.0019e-06 - accuracy: 1.0000 - val_loss: 5.3846 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 8s 509ms/step - loss: 1.4272e-06 - accuracy: 1.0000 - val_loss: 5.3848 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 9s 567ms/step - loss: 2.0857e-06 - accuracy: 1.0000 - val_loss: 5.3853 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 9s 585ms/step - loss: 1.2538e-06 - accuracy: 1.0000 - val_loss: 5.3852 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 9s 594ms/step - loss: 2.2995e-06 - accuracy: 1.0000 - val_loss: 5.3855 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 9s 598ms/step - loss: 2.3118e-06 - accuracy: 1.0000 - val_loss: 5.3861 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 8s 499ms/step - loss: 1.9205e-06 - accuracy: 1.0000 - val_loss: 5.3864 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 9s 606ms/step - loss: 1.9509e-06 - accuracy: 1.0000 - val_loss: 5.3864 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 8s 524ms/step - loss: 1.1740e-06 - accuracy: 1.0000 - val_loss: 5.3866 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 8s 547ms/step - loss: 1.6952e-06 - accuracy: 1.0000 - val_loss: 5.3873 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 8s 563ms/step - loss: 1.3993e-06 - accuracy: 1.0000 - val_loss: 5.3885 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 8s 544ms/step - loss: 1.5357e-06 - accuracy: 1.0000 - val_loss: 5.3884 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 8s 551ms/step - loss: 2.1852e-06 - accuracy: 1.0000 - val_loss: 5.3886 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 8s 546ms/step - loss: 2.9966e-06 - accuracy: 1.0000 - val_loss: 5.3882 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 8s 552ms/step - loss: 1.6130e-06 - accuracy: 1.0000 - val_loss: 5.3889 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 8s 537ms/step - loss: 1.4691e-06 - accuracy: 1.0000 - val_loss: 5.3884 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 8s 560ms/step - loss: 2.0035e-06 - accuracy: 1.0000 - val_loss: 5.3886 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 10s 643ms/step - loss: 1.3804e-06 - accuracy: 1.0000 - val_loss: 5.3877 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 9s 608ms/step - loss: 1.4642e-06 - accuracy: 1.0000 - val_loss: 5.3876 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 8s 512ms/step - loss: 1.8095e-06 - accuracy: 1.0000 - val_loss: 5.3876 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 7s 502ms/step - loss: 2.7911e-06 - accuracy: 1.0000 - val_loss: 5.3863 - val_accuracy: 0.6111 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 1.1411e-06 - accuracy: 1.0000 - val_loss: 5.3857 - val_accuracy: 0.6111 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True,random_state=42) # 5折交叉验证\n",
    "\n",
    "i = 1\n",
    "a=[]\n",
    "h=np.asarray(Data)\n",
    "Label=np.asarray(Label)\n",
    "for train_index, test_index in kf.split(h, Label):\n",
    "    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "    X_train, X_test = h[train_index], h[test_index] \n",
    "    y_train, y_test = Label[train_index], Label[test_index]\n",
    "    model=built_model()\n",
    "    history=model.fit(X_train,y_train,batch_size=10,epochs=100,validation_data=(X_test,y_test),callbacks=[reduce_lr])\n",
    "    x=np.asarray(history.history['accuracy']), \n",
    "    y=np.asarray(history.history['val_accuracy'])\n",
    "    b=np.asarray(y)\n",
    "    a.append(b.max())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8f0d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405405402183533\n"
     ]
    }
   ],
   "source": [
    "a=np.asarray(a)\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b9710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n",
    "\n",
    "def Train_Val_Plot(acc,val_acc,loss,val_loss):\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (20,5))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(acc) + 1), acc)\n",
    "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "    ax1.set_title('History of Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    ax2.plot(range(1, len(loss) + 1), loss)\n",
    "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax2.set_title('History of Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
    "               history.history['loss'],history.history['val_loss'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ae6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed56c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac3ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95bfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf36768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 位置编码信息\n",
    "def positional_embedding(maxlen, model_size):\n",
    "    PE = np.zeros((maxlen, model_size))\n",
    "    for i in range(maxlen):\n",
    "        for j in range(model_size):\n",
    "            if j % 2 == 0:\n",
    "                PE[i, j] = np.sin(i / 10000 ** (j / model_size))\n",
    "            else:\n",
    "                PE[i, j] = np.cos(i / 10000 ** ((j-1) / model_size))\n",
    "    PE = tf.constant(PE, dtype=tf.float32)\n",
    "    return PE\n",
    "\n",
    "class MultiHeadAttention(keras.Model):\n",
    "    def __init__(self, model_size, num_heads, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "\n",
    "        self.model_size = model_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = model_size // num_heads\n",
    "        self.WQ = keras.layers.Dense(model_size, name=\"dense_query\")\n",
    "        self.WK = keras.layers.Dense(model_size, name=\"dense_key\")\n",
    "        self.WV = keras.layers.Dense(model_size, name=\"dense_value\")\n",
    "        self.dense = keras.layers.Dense(model_size)\n",
    "\n",
    "    def call(self, query, key, value, mask):\n",
    "        # query: (batch, maxlen, model_size)\n",
    "        # key  : (batch, maxlen, model_size)\n",
    "        # value: (batch, maxlen, model_size)\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # shape: (batch, maxlen, model_size)\n",
    "        query = self.WQ(query)\n",
    "        key = self.WK(key)\n",
    "        value = self.WV(value)\n",
    "\n",
    "        def _split_heads(x):\n",
    "            x = tf.reshape(x, shape=[batch_size, -1, self.num_heads, self.head_size])\n",
    "            return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # shape: (batch, num_heads, maxlen, head_size)\n",
    "        query = _split_heads(query)\n",
    "        key = _split_heads(key)\n",
    "        value = _split_heads(value)\n",
    "\n",
    "        # shape: (batch, num_heads, maxlen, maxlen)\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        # 缩放 matmul_qk\n",
    "        dk = tf.cast(query.shape[-1], tf.float32)\n",
    "        score = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            # mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=tf.float32)\n",
    "            score += (1 - mask) * -1e9\n",
    "\n",
    "        alpha = tf.nn.softmax(score)\n",
    "        context = tf.matmul(alpha, value)\n",
    "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
    "        context = tf.reshape(context, (batch_size, -1, self.model_size))\n",
    "        output = self.dense(context)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    # position-wise feed forward network\n",
    "class FeedForwardNetwork(keras.Model):\n",
    "    def __init__(self, dff_size, model_size):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(dff_size, activation=\"relu\")\n",
    "        self.dense2 = keras.layers.Dense(model_size)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "    # Encoder Layer层\n",
    "class EncoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, model_size, num_heads, dff_size, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(model_size, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(dff_size, model_size)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        # multi head attention\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # residual connection\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        # ffn layer\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        # Residual connection\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "# 多层Encoder\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, model_size)\n",
    "        self.pos_embedding = positional_embedding(maxlen, model_size)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(model_size,num_heads,dff_size,rate) for _ in range(num_layers)]\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, padding_mask):\n",
    "        # input embedding + positional embedding\n",
    "        x = self.embedding(x) + self.pos_embedding\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, padding_mask)\n",
    "        return x\n",
    "# Decoder Layer\n",
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, model_size, num_heads, dff_size, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mask_attention = MultiHeadAttention(model_size, num_heads)\n",
    "        self.attention = MultiHeadAttention(model_size, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(dff_size, model_size)\n",
    "        \n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn_decoder = self.mask_attention(x, x, x, look_ahead_mask)\n",
    "        attn_decoder = self.dropout1(attn_decoder, training=training)\n",
    "        out1 = self.layernorm1(x + attn_decoder)\n",
    "        \n",
    "        attn_encoder_decoder = self.attention(out1, enc_output, enc_output, padding_mask)\n",
    "        attn_encoder_decoder = self.dropout2(attn_encoder_decoder, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn_encoder_decoder)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "        \n",
    "        return out3\n",
    "# 多层Decoder\n",
    "class Decoder(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, model_size)\n",
    "        self.pos_embedding = positional_embedding(maxlen, model_size)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(model_size,num_heads,dff_size,rate) for _ in range(num_layers)]\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, enc_output, x, training, look_ahead_mask, padding_mask):\n",
    "        # input embedding + positional embedding\n",
    "        x = self.embedding(x) + self.pos_embedding\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.decoder_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "            \n",
    "        return x\n",
    "# padding填充mask\n",
    "def padding_mask(seq):\n",
    "    mask = tf.cast(tf.math.not_equal(seq, 0), dtype=tf.float32)\n",
    "    mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "    return mask\n",
    "'''\n",
    "-------------------\n",
    ">> inputs = tf.constant([[1,2,3,0],[4,5,0,0]])\n",
    ">> mask = padding_mask(inputs)\n",
    "tf.Tensor(\n",
    "[[[[1. 1. 1. 0.]]]\n",
    " [[[1. 1. 0. 0.]]]], shape=(2, 1, 1, 4), dtype=float32)\n",
    "-------------------\n",
    "'''\n",
    "\n",
    "# decode mask\n",
    "def look_ahead_mask(size):\n",
    "    ahead_mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    ahead_mask = tf.cast(ahead_mask, dtype=tf.float32)\n",
    "    return ahead_mask\n",
    "'''\n",
    "-------------------\n",
    ">> inputs = tf.constant(4)\n",
    ">> mask = look_ahead_mask(inputs)\n",
    "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
    "array([[1., 0., 0., 0.],\n",
    "       [1., 1., 0., 0.],\n",
    "       [1., 1., 1., 0.],\n",
    "       [1., 1., 1., 1.]], dtype=float32)>\n",
    "-------------------\n",
    "'''\n",
    "\n",
    "def create_mask(inp, tar):\n",
    "    enc_padding_mask = padding_mask(inp)\n",
    "    dec_padding_mask = padding_mask(tar)\n",
    "    ahead_mask = look_ahead_mask(tf.shape(tar)[1])\n",
    "    combined_mask = tf.minimum(dec_padding_mask, ahead_mask)\n",
    "    return enc_padding_mask, dec_padding_mask, combined_mask\n",
    "\n",
    "# Encoder和Decoder组合成Transformer\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, training=True, rete=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.training = training\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "        self.decoder = Decoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "        self.final_dense = keras.layers.Dense(vocab_size, name=\"final_output\")\n",
    "        \n",
    "    def call(self, all_inputs):\n",
    "        sources, targets = all_inputs\n",
    "\n",
    "        enc_padding_mask, dec_padding_mask, combined_mask = create_mask(sources, targets)\n",
    "\n",
    "        enc_output = self.encoder(sources, self.training, enc_padding_mask)\n",
    "        dec_output = self.decoder(enc_output, targets, self.training, combined_mask , dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_dense(dec_output)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "722375b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " enc_input (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dec_input (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " transformer_9 (Transformer)    (None, 10, 10000)    64026384    ['enc_input[0][0]',              \n",
      "                                                                  'dec_input[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,026,384\n",
      "Trainable params: 64,026,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "model_size = 768\n",
    "num_heads = 12\n",
    "dff_size = 1024\n",
    "maxlen = 10\n",
    "vocab_size = 10000\n",
    "\n",
    "enc_inputs = keras.layers.Input(shape=(maxlen,), name=\"enc_input\")\n",
    "dec_inputs = keras.layers.Input(shape=(maxlen,), name=\"dec_input\")\n",
    "dec_outputs = keras.layers.Input(shape=(maxlen,), name=\"dec_output\")\n",
    "\n",
    "transformer = Transformer(num_layers=num_layers, \n",
    "                        model_size=model_size, \n",
    "                        num_heads=num_heads, \n",
    "                        dff_size=dff_size, \n",
    "                        vocab_size=vocab_size, \n",
    "                        maxlen=maxlen)\n",
    "final_output = transformer([enc_inputs, dec_inputs])\n",
    "\n",
    "model = keras.models.Model(inputs=[enc_inputs, dec_inputs], outputs=final_output)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc538ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98759494",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"transformer_9\" (type Transformer).\n\nIndex out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: model_2/transformer_9/strided_slice/\n\nCall arguments received:\n  • all_inputs=['tf.Tensor(shape=(90,), dtype=float32)', 'tf.Tensor(shape=(2,), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BRYANT~1\\AppData\\Local\\Temp/ipykernel_6444/3731599107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\kobe\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BRYANT~1\\AppData\\Local\\Temp/ipykernel_6444/1526755264.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, all_inputs)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0menc_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0menc_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BRYANT~1\\AppData\\Local\\Temp/ipykernel_6444/1526755264.py\u001b[0m in \u001b[0;36mcreate_mask\u001b[1;34m(inp, tar)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0menc_padding_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mdec_padding_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mahead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BRYANT~1\\AppData\\Local\\Temp/ipykernel_6444/1526755264.py\u001b[0m in \u001b[0;36mpadding_mask\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m '''\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"transformer_9\" (type Transformer).\n\nIndex out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: model_2/transformer_9/strided_slice/\n\nCall arguments received:\n  • all_inputs=['tf.Tensor(shape=(90,), dtype=float32)', 'tf.Tensor(shape=(2,), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "model((Data[0][0],Label[0:10][1]),Label[0:10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1a943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c4c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b031176f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ddf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754c7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f91c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.00392460823059082\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() #layers [200,50,50,50,50,1]\n",
    "model.add(LSTM(input_shape=(None,90),units=200,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.LayerNormalization())\n",
    "model.add(LSTM(input_shape=(None,50),units=200,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.LayerNormalization())\n",
    "model.add(LSTM(input_shape=(None,50),units=90,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.LayerNormalization())\n",
    "model.add(LSTM(50,return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.LayerNormalization())\n",
    "model.add(Dense(units=4))\n",
    "#model.add(Activation(\"linear\"))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "start = time.time()\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics='accuracy')\n",
    "print(\"Compilation Time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Train.transpose((0,2,1)),label_train,batch_size=5,epochs=50,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cdb7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 160ms/step - loss: 0.4157 - accuracy: 0.2727\n",
      "0.27272728085517883\n"
     ]
    }
   ],
   "source": [
    "loss,acu = model.evaluate(Test.transpose((0,2,1)),label_test)\n",
    "print(acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
